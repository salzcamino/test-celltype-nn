{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CellType-NN Example Usage\n",
    "\n",
    "This notebook demonstrates how to use the CellType-NN framework for cell type prediction from single-cell RNA-seq data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../src')\n",
    "\n",
    "import scanpy as sc\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from celltype_nn.data.loader import create_dataloaders\n",
    "from celltype_nn.preprocessing.preprocess import preprocess_rna\n",
    "from celltype_nn.models.rna_classifier import RNAClassifier\n",
    "from celltype_nn.training.lightning_module import CellTypeClassifierModule\n",
    "from celltype_nn.evaluation.metrics import evaluate_model, plot_confusion_matrix\n",
    "\n",
    "# Set random seed\n",
    "pl.seed_everything(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Preprocess Data\n",
    "\n",
    "For this example, we'll use a publicly available dataset. Replace with your own data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Load PBMC dataset from scanpy\n",
    "adata = sc.datasets.pbmc3k()\n",
    "\n",
    "# Basic QC and preprocessing\n",
    "sc.pp.filter_cells(adata, min_genes=200)\n",
    "sc.pp.filter_genes(adata, min_cells=3)\n",
    "\n",
    "# Add example cell type labels (in real data, these would be from annotation)\n",
    "# For demo, we'll use Leiden clustering\n",
    "sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "sc.pp.log1p(adata)\n",
    "sc.pp.highly_variable_genes(adata, n_top_genes=2000)\n",
    "sc.pp.pca(adata)\n",
    "sc.pp.neighbors(adata)\n",
    "sc.tl.leiden(adata, resolution=0.5)\n",
    "adata.obs['cell_type'] = adata.obs['leiden']\n",
    "\n",
    "print(f\"Dataset: {adata.n_obs} cells x {adata.n_vars} genes\")\n",
    "print(f\"Cell types: {adata.obs['cell_type'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess for Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data\n",
    "adata_processed = preprocess_rna(\n",
    "    adata,\n",
    "    n_top_genes=2000,\n",
    "    normalize=True,\n",
    "    log_transform=True,\n",
    "    scale=False  # Don't scale for neural networks\n",
    ")\n",
    "\n",
    "# Subset to highly variable genes\n",
    "adata_hvg = adata_processed[:, adata_processed.var['highly_variable']].copy()\n",
    "\n",
    "print(f\"Using {adata_hvg.n_vars} highly variable genes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train/val/test splits\n",
    "dataloaders = create_dataloaders(\n",
    "    adata_hvg,\n",
    "    label_key='cell_type',\n",
    "    batch_size=128,\n",
    "    train_size=0.7,\n",
    "    val_size=0.15,\n",
    "    test_size=0.15,\n",
    "    stratify=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "train_dataset = dataloaders['datasets']['train']\n",
    "print(f\"Number of classes: {train_dataset.num_classes}\")\n",
    "print(f\"Number of features: {train_dataset.num_features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "model = RNAClassifier(\n",
    "    input_dim=train_dataset.num_features,\n",
    "    num_classes=train_dataset.num_classes,\n",
    "    hidden_dims=[256, 128, 64],\n",
    "    dropout_rate=0.3,\n",
    "    batch_norm=True,\n",
    "    activation='relu'\n",
    ")\n",
    "\n",
    "print(f\"Model architecture:\\n{model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Lightning Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Lightning module\n",
    "lightning_module = CellTypeClassifierModule(\n",
    "    model=model,\n",
    "    num_classes=train_dataset.num_classes,\n",
    "    learning_rate=1e-3,\n",
    "    weight_decay=1e-5,\n",
    "    optimizer='adamw',\n",
    "    scheduler='cosine'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# Setup callbacks\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val/loss',\n",
    "    mode='min',\n",
    "    save_top_k=1,\n",
    "    filename='best-model'\n",
    ")\n",
    "\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor='val/loss',\n",
    "    patience=10,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "# Create trainer\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=50,\n",
    "    accelerator='auto',\n",
    "    devices=1,\n",
    "    callbacks=[checkpoint_callback, early_stop_callback],\n",
    "    log_every_n_steps=10\n",
    ")\n",
    "\n",
    "# Train\n",
    "trainer.fit(\n",
    "    lightning_module,\n",
    "    train_dataloaders=dataloaders['train'],\n",
    "    val_dataloaders=dataloaders['val']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "test_results = trainer.test(lightning_module, dataloaders=dataloaders['test'])\n",
    "print(test_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detailed Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get label names\n",
    "label_names = [train_dataset.get_label_name(i) for i in range(train_dataset.num_classes)]\n",
    "\n",
    "# Evaluate model\n",
    "results = evaluate_model(\n",
    "    lightning_module.model,\n",
    "    dataloaders['test'],\n",
    "    label_names=label_names\n",
    ")\n",
    "\n",
    "print(\"\\nTest Metrics:\")\n",
    "for metric, value in results['metrics'].items():\n",
    "    if not metric.startswith('f1_') or metric in ['f1_macro', 'f1_micro', 'f1_weighted']:\n",
    "        print(f\"  {metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "plot_confusion_matrix(\n",
    "    results['labels'],\n",
    "    results['predictions'],\n",
    "    label_names=label_names,\n",
    "    normalize=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Predictions on New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions and probabilities\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Example: predict on a batch\n",
    "batch = next(iter(dataloaders['test']))\n",
    "features = batch['features']\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = lightning_module.model(features)\n",
    "    probs = F.softmax(logits, dim=1)\n",
    "    preds = torch.argmax(probs, dim=1)\n",
    "\n",
    "# Convert to cell type names\n",
    "predicted_types = [label_names[p.item()] for p in preds]\n",
    "print(f\"Predicted cell types: {predicted_types[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save checkpoint\n",
    "trainer.save_checkpoint(\"final_model.ckpt\")\n",
    "print(\"Model saved to final_model.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model for Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from checkpoint\n",
    "loaded_module = CellTypeClassifierModule.load_from_checkpoint(\n",
    "    \"final_model.ckpt\",\n",
    "    model=model\n",
    ")\n",
    "loaded_module.eval()\n",
    "print(\"Model loaded successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
