{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# CellType-NN Demo: Cell Type Prediction with Deep Learning\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/yourusername/celltype-nn/blob/main/notebooks/celltype_nn_demo.ipynb)\n",
    "\n",
    "This notebook demonstrates how to use CellType-NN for automated cell type prediction from single-cell RNA-seq data using deep learning.\n",
    "\n",
    "## What you'll learn:\n",
    "- Generate synthetic single-cell data for testing\n",
    "- Preprocess scRNA-seq data\n",
    "- Train a neural network classifier\n",
    "- Evaluate model performance\n",
    "- Visualize results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup"
   },
   "source": [
    "## 1. Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_deps"
   },
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q torch torchvision torchaudio\n",
    "!pip install -q pytorch-lightning\n",
    "!pip install -q scanpy anndata muon\n",
    "!pip install -q scikit-learn matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "clone_repo"
   },
   "outputs": [],
   "source": [
    "# Clone the CellType-NN repository\n",
    "!git clone https://github.com/salzcamino/test-celltype-nn.git\n",
    "%cd test-celltype-nn\n",
    "!pip install -q -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "imports"
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Import CellType-NN modules\n",
    "from celltype_nn.data.loader import load_anndata, split_anndata, create_dataloaders\n",
    "from celltype_nn.preprocessing.preprocess import preprocess_rna\n",
    "from celltype_nn.models.rna_classifier import RNAClassifier\n",
    "from celltype_nn.training.lightning_module import CellTypeClassifierModule\n",
    "from celltype_nn.evaluation.metrics import (\n",
    "    calculate_metrics,\n",
    "    plot_confusion_matrix,\n",
    "    plot_per_class_metrics\n",
    ")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "pl.seed_everything(42)\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "print(\"✓ All imports successful!\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"GPU available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "data_generation"
   },
   "source": [
    "## 2. Generate Synthetic Single-Cell Data\n",
    "\n",
    "We'll create a synthetic dataset with 5 cell types and realistic gene expression patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "generate_data"
   },
   "outputs": [],
   "source": [
    "def generate_synthetic_scrna_data(n_cells=2000, n_genes=2000, n_cell_types=5, seed=42):\n",
    "    \"\"\"\n",
    "    Generate synthetic single-cell RNA-seq data.\n",
    "    \n",
    "    Creates realistic count data with:\n",
    "    - Cell type-specific marker genes\n",
    "    - Biological variability\n",
    "    - Dropout events (zeros)\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Define cell types\n",
    "    cell_types = [f'CellType_{i+1}' for i in range(n_cell_types)]\n",
    "    cells_per_type = n_cells // n_cell_types\n",
    "    \n",
    "    # Create cell type labels\n",
    "    cell_type_labels = []\n",
    "    for ct in cell_types:\n",
    "        cell_type_labels.extend([ct] * cells_per_type)\n",
    "    \n",
    "    # Generate base expression (negative binomial for realistic count data)\n",
    "    base_expression = np.random.negative_binomial(5, 0.3, size=(n_cells, n_genes))\n",
    "    \n",
    "    # Add cell type-specific signatures\n",
    "    markers_per_type = n_genes // (n_cell_types * 2)  # 10% of genes are markers\n",
    "    \n",
    "    for i, ct in enumerate(cell_types):\n",
    "        start_cell = i * cells_per_type\n",
    "        end_cell = (i + 1) * cells_per_type\n",
    "        \n",
    "        # Select marker genes for this cell type\n",
    "        marker_start = i * markers_per_type\n",
    "        marker_end = (i + 1) * markers_per_type\n",
    "        \n",
    "        # Increase expression of marker genes\n",
    "        base_expression[start_cell:end_cell, marker_start:marker_end] += \\\n",
    "            np.random.negative_binomial(10, 0.2, \n",
    "                                       size=(cells_per_type, markers_per_type))\n",
    "    \n",
    "    # Add dropout (set some values to zero)\n",
    "    dropout_mask = np.random.random((n_cells, n_genes)) < 0.3\n",
    "    base_expression[dropout_mask] = 0\n",
    "    \n",
    "    # Create AnnData object\n",
    "    adata = sc.AnnData(\n",
    "        X=base_expression,\n",
    "        obs=pd.DataFrame({\n",
    "            'cell_type': cell_type_labels,\n",
    "            'n_counts': base_expression.sum(axis=1),\n",
    "            'n_genes': (base_expression > 0).sum(axis=1)\n",
    "        }),\n",
    "        var=pd.DataFrame(index=[f'Gene_{i}' for i in range(n_genes)])\n",
    "    )\n",
    "    \n",
    "    return adata\n",
    "\n",
    "\n",
    "# Generate synthetic dataset\n",
    "print(\"Generating synthetic single-cell data...\")\n",
    "adata = generate_synthetic_scrna_data(\n",
    "    n_cells=2000,\n",
    "    n_genes=2000,\n",
    "    n_cell_types=5,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ Generated dataset:\")\n",
    "print(f\"  Cells: {adata.n_obs}\")\n",
    "print(f\"  Genes: {adata.n_vars}\")\n",
    "print(f\"  Cell types: {adata.obs['cell_type'].nunique()}\")\n",
    "print(f\"\\nCell type distribution:\")\n",
    "print(adata.obs['cell_type'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "visualize_raw"
   },
   "source": [
    "### Visualize Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "plot_raw"
   },
   "outputs": [],
   "source": [
    "# Quick visualization of the raw data\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Cell type distribution\n",
    "adata.obs['cell_type'].value_counts().plot(kind='bar', ax=axes[0], color='steelblue')\n",
    "axes[0].set_title('Cell Type Distribution', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Cell Type')\n",
    "axes[0].set_ylabel('Number of Cells')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Total counts per cell\n",
    "axes[1].hist(adata.obs['n_counts'], bins=50, color='coral', alpha=0.7)\n",
    "axes[1].set_title('Total Counts per Cell', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Total Counts')\n",
    "axes[1].set_ylabel('Number of Cells')\n",
    "\n",
    "# Genes per cell\n",
    "axes[2].hist(adata.obs['n_genes'], bins=50, color='seagreen', alpha=0.7)\n",
    "axes[2].set_title('Genes Detected per Cell', fontsize=14, fontweight='bold')\n",
    "axes[2].set_xlabel('Number of Genes')\n",
    "axes[2].set_ylabel('Number of Cells')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "preprocessing"
   },
   "source": [
    "## 3. Data Preprocessing\n",
    "\n",
    "Preprocessing steps:\n",
    "1. Quality control filtering\n",
    "2. Normalization (CPM + log transform)\n",
    "3. Highly variable gene selection\n",
    "4. Data splitting (train/val/test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "preprocess"
   },
   "outputs": [],
   "source": [
    "# Preprocess the data\n",
    "print(\"Preprocessing data...\")\n",
    "\n",
    "adata_processed = preprocess_rna(\n",
    "    adata.copy(),\n",
    "    n_top_genes=500,  # Select 500 highly variable genes\n",
    "    min_genes=50,\n",
    "    min_cells=3,\n",
    "    normalize=True,\n",
    "    log_transform=True,\n",
    "    target_sum=1e4\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ Preprocessed dataset:\")\n",
    "print(f\"  Cells after filtering: {adata_processed.n_obs}\")\n",
    "print(f\"  Highly variable genes: {len(adata_processed.var_names)}\")\n",
    "print(f\"  Data shape: {adata_processed.X.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "split_data"
   },
   "outputs": [],
   "source": [
    "# Split into train/validation/test sets\n",
    "print(\"\\nSplitting data...\")\n",
    "\n",
    "train_adata, val_adata, test_adata = split_anndata(\n",
    "    adata_processed,\n",
    "    train_size=0.7,\n",
    "    val_size=0.15,\n",
    "    test_size=0.15,\n",
    "    stratify_key='cell_type',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ Data split:\")\n",
    "print(f\"  Training set: {train_adata.n_obs} cells\")\n",
    "print(f\"  Validation set: {val_adata.n_obs} cells\")\n",
    "print(f\"  Test set: {test_adata.n_obs} cells\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_loaders"
   },
   "outputs": [],
   "source": [
    "# Create PyTorch data loaders\n",
    "print(\"\\nCreating data loaders...\")\n",
    "\n",
    "train_loader = create_dataloaders(\n",
    "    train_adata,\n",
    "    label_key='cell_type',\n",
    "    batch_size=64,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_loader = create_dataloaders(\n",
    "    val_adata,\n",
    "    label_key='cell_type',\n",
    "    batch_size=64,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_loader = create_dataloaders(\n",
    "    test_adata,\n",
    "    label_key='cell_type',\n",
    "    batch_size=64,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ Data loaders created!\")\n",
    "print(f\"  Number of classes: {len(train_adata.obs['cell_type'].unique())}\")\n",
    "print(f\"  Input features: {train_adata.n_vars}\")\n",
    "print(f\"  Batch size: 64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "model_training"
   },
   "source": [
    "## 4. Model Training\n",
    "\n",
    "We'll train a feedforward neural network with:\n",
    "- 3 hidden layers (512, 256, 128)\n",
    "- Batch normalization and dropout\n",
    "- Adam optimizer\n",
    "- Early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_model"
   },
   "outputs": [],
   "source": [
    "# Get number of features and classes\n",
    "input_dim = train_adata.n_vars\n",
    "num_classes = len(train_adata.obs['cell_type'].unique())\n",
    "\n",
    "# Create model\n",
    "model = RNAClassifier(\n",
    "    input_dim=input_dim,\n",
    "    num_classes=num_classes,\n",
    "    hidden_dims=[512, 256, 128],\n",
    "    dropout_rate=0.3,\n",
    "    activation='relu',\n",
    "    batch_norm=True\n",
    ")\n",
    "\n",
    "# Wrap in Lightning module\n",
    "lit_model = CellTypeClassifierModule(\n",
    "    model=model,\n",
    "    learning_rate=1e-3,\n",
    "    optimizer='adam',\n",
    "    scheduler='cosine',\n",
    "    num_classes=num_classes\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ Model created:\")\n",
    "print(f\"  Input dimension: {input_dim}\")\n",
    "print(f\"  Output classes: {num_classes}\")\n",
    "print(f\"  Hidden layers: [512, 256, 128]\")\n",
    "print(f\"  Total parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "train_model"
   },
   "outputs": [],
   "source": [
    "# Setup trainer\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=50,\n",
    "    accelerator='auto',\n",
    "    devices=1,\n",
    "    callbacks=[\n",
    "        pl.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=10,\n",
    "            mode='min'\n",
    "        ),\n",
    "        pl.callbacks.ModelCheckpoint(\n",
    "            monitor='val_accuracy',\n",
    "            mode='max',\n",
    "            save_top_k=1\n",
    "        )\n",
    "    ],\n",
    "    enable_progress_bar=True,\n",
    "    log_every_n_steps=10\n",
    ")\n",
    "\n",
    "# Train model\n",
    "print(\"\\nStarting training...\\n\")\n",
    "trainer.fit(lit_model, train_loader, val_loader)\n",
    "print(\"\\n✓ Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "evaluation"
   },
   "source": [
    "## 5. Model Evaluation\n",
    "\n",
    "Evaluate the trained model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "test_model"
   },
   "outputs": [],
   "source": [
    "# Test the model\n",
    "print(\"Evaluating on test set...\\n\")\n",
    "test_results = trainer.test(lit_model, test_loader)\n",
    "\n",
    "print(f\"\\n✓ Test Results:\")\n",
    "print(f\"  Test Accuracy: {test_results[0]['test_accuracy']:.4f}\")\n",
    "print(f\"  Test Loss: {test_results[0]['test_loss']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "get_predictions"
   },
   "outputs": [],
   "source": [
    "# Get predictions for detailed analysis\n",
    "lit_model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "all_probs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        features, labels = batch\n",
    "        logits = lit_model(features)\n",
    "        probs = torch.softmax(logits, dim=1)\n",
    "        preds = torch.argmax(probs, dim=1)\n",
    "        \n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "all_preds = np.array(all_preds)\n",
    "all_labels = np.array(all_labels)\n",
    "all_probs = np.array(all_probs)\n",
    "\n",
    "# Get class names\n",
    "class_names = sorted(test_adata.obs['cell_type'].unique())\n",
    "\n",
    "print(\"✓ Predictions generated!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "visualizations"
   },
   "source": [
    "## 6. Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "confusion_matrix"
   },
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt='d',\n",
    "    cmap='Blues',\n",
    "    xticklabels=class_names,\n",
    "    yticklabels=class_names,\n",
    "    cbar_kws={'label': 'Count'}\n",
    ")\n",
    "plt.title('Confusion Matrix', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.xlabel('Predicted Cell Type', fontsize=12)\n",
    "plt.ylabel('True Cell Type', fontsize=12)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "classification_report"
   },
   "outputs": [],
   "source": [
    "# Classification Report\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(\n",
    "    all_labels,\n",
    "    all_preds,\n",
    "    target_names=class_names,\n",
    "    digits=4\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "per_class_accuracy"
   },
   "outputs": [],
   "source": [
    "# Per-class accuracy visualization\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "precision, recall, f1, support = precision_recall_fscore_support(\n",
    "    all_labels, all_preds, average=None\n",
    ")\n",
    "\n",
    "# Create DataFrame for plotting\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Cell Type': class_names,\n",
    "    'Precision': precision,\n",
    "    'Recall': recall,\n",
    "    'F1-Score': f1\n",
    "})\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "x = np.arange(len(class_names))\n",
    "width = 0.25\n",
    "\n",
    "ax.bar(x - width, metrics_df['Precision'], width, label='Precision', color='steelblue')\n",
    "ax.bar(x, metrics_df['Recall'], width, label='Recall', color='coral')\n",
    "ax.bar(x + width, metrics_df['F1-Score'], width, label='F1-Score', color='seagreen')\n",
    "\n",
    "ax.set_xlabel('Cell Type', fontsize=12)\n",
    "ax.set_ylabel('Score', fontsize=12)\n",
    "ax.set_title('Per-Class Performance Metrics', fontsize=16, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(class_names, rotation=45, ha='right')\n",
    "ax.legend()\n",
    "ax.set_ylim([0, 1.1])\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "prediction_confidence"
   },
   "outputs": [],
   "source": [
    "# Prediction confidence distribution\n",
    "max_probs = all_probs.max(axis=1)\n",
    "correct = (all_preds == all_labels)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "ax.hist(max_probs[correct], bins=50, alpha=0.6, label='Correct', color='green')\n",
    "ax.hist(max_probs[~correct], bins=50, alpha=0.6, label='Incorrect', color='red')\n",
    "\n",
    "ax.set_xlabel('Prediction Confidence', fontsize=12)\n",
    "ax.set_ylabel('Number of Predictions', fontsize=12)\n",
    "ax.set_title('Prediction Confidence Distribution', fontsize=16, fontweight='bold')\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nAverage confidence for correct predictions: {max_probs[correct].mean():.4f}\")\n",
    "print(f\"Average confidence for incorrect predictions: {max_probs[~correct].mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "summary"
   },
   "source": [
    "## 7. Summary\n",
    "\n",
    "In this notebook, we:\n",
    "\n",
    "1. ✓ Generated synthetic single-cell RNA-seq data with 5 cell types\n",
    "2. ✓ Preprocessed the data (normalization, HVG selection)\n",
    "3. ✓ Split data into train/validation/test sets\n",
    "4. ✓ Trained a neural network classifier\n",
    "5. ✓ Evaluated model performance with multiple metrics\n",
    "6. ✓ Visualized results (confusion matrix, per-class metrics, confidence)\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "- Try with your own single-cell data\n",
    "- Experiment with different architectures (attention, VAE)\n",
    "- Test multi-modal models (RNA + protein + ATAC)\n",
    "- Apply batch correction for multi-batch datasets\n",
    "- Fine-tune hyperparameters\n",
    "\n",
    "### Resources:\n",
    "\n",
    "- [CellType-NN Documentation](https://github.com/salzcamino/test-celltype-nn)\n",
    "- [Python README](https://github.com/salzcamino/test-celltype-nn/blob/main/README.md)\n",
    "- [R Implementation](https://github.com/salzcamino/test-celltype-nn/blob/main/R_README.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "save_model"
   },
   "outputs": [],
   "source": [
    "# Optional: Save the trained model\n",
    "# torch.save(lit_model.state_dict(), 'celltype_classifier.pth')\n",
    "# print(\"✓ Model saved to celltype_classifier.pth\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
